## NOTE: This chunk will use your model from q4; it will predict on the
##       validation data, add prediction intervals for every prediction,
##       and visualize the results on a predicted-vs-actual plot. It will
##       also compare against the simple `fit_simple` defined above.
bind_rows(
df_validate %>%
add_uncertainties(fit_simple, interval = "prediction", prefix = "pi") %>%
select(T_norm, pi_lwr, pi_fit, pi_upr) %>%
mutate(model = "x only"),
df_validate %>%
add_uncertainties(fit_q4, interval = "prediction", prefix = "pi") %>%
select(T_norm, pi_lwr, pi_fit, pi_upr) %>%
mutate(model = "q4"),
) %>%
ggplot(aes(T_norm, pi_fit)) +
geom_abline(slope = 1, intercept = 0, color = "grey80", size = 2) +
geom_errorbar(
aes(ymin = pi_lwr, ymax = pi_upr),
width = 0
) +
geom_point() +
facet_grid(~ model, labeller = label_both) +
theme_minimal() +
labs(
title = "Predicted vs Actual",
x = "Actual T_norm",
y = "Predicted T_norm"
)
## TODO: Fit a model for T_norm using only *principled* predictors, try to
##       optimize your validation error.
fit_q4 <- lm(T_norm ~ x + U_0 + avg_T, data = df_train)
## NOTE: No need to change these error calculations; use them to
##       help define your model
rsquare(fit_q4, df_train)
rsquare(fit_q4, df_validate)
## TODO: Run this code and interpret the results
## NOTE: No need to edit this chunk
## NOTE: This chunk will use your model from q4; it will predict on the
##       validation data, add prediction intervals for every prediction,
##       and visualize the results on a predicted-vs-actual plot. It will
##       also compare against the simple `fit_simple` defined above.
bind_rows(
df_validate %>%
add_uncertainties(fit_simple, interval = "prediction", prefix = "pi") %>%
select(T_norm, pi_lwr, pi_fit, pi_upr) %>%
mutate(model = "x only"),
df_validate %>%
add_uncertainties(fit_q4, interval = "prediction", prefix = "pi") %>%
select(T_norm, pi_lwr, pi_fit, pi_upr) %>%
mutate(model = "q4"),
) %>%
ggplot(aes(T_norm, pi_fit)) +
geom_abline(slope = 1, intercept = 0, color = "grey80", size = 2) +
geom_errorbar(
aes(ymin = pi_lwr, ymax = pi_upr),
width = 0
) +
geom_point() +
facet_grid(~ model, labeller = label_both) +
theme_minimal() +
labs(
title = "Predicted vs Actual",
x = "Actual T_norm",
y = "Predicted T_norm"
)
## TODO: Fit a model for T_norm using only *principled* predictors, try to
##       optimize your validation error.
fit_q4 <- lm(T_norm ~ x + U_0 + avg_T + idx, data = df_train)
## NOTE: No need to change these error calculations; use them to
##       help define your model
rsquare(fit_q4, df_train)
rsquare(fit_q4, df_validate)
## TODO: Run this code and interpret the results
## NOTE: No need to edit this chunk
## NOTE: This chunk will use your model from q4; it will predict on the
##       validation data, add prediction intervals for every prediction,
##       and visualize the results on a predicted-vs-actual plot. It will
##       also compare against the simple `fit_simple` defined above.
bind_rows(
df_validate %>%
add_uncertainties(fit_simple, interval = "prediction", prefix = "pi") %>%
select(T_norm, pi_lwr, pi_fit, pi_upr) %>%
mutate(model = "x only"),
df_validate %>%
add_uncertainties(fit_q4, interval = "prediction", prefix = "pi") %>%
select(T_norm, pi_lwr, pi_fit, pi_upr) %>%
mutate(model = "q4"),
) %>%
ggplot(aes(T_norm, pi_fit)) +
geom_abline(slope = 1, intercept = 0, color = "grey80", size = 2) +
geom_errorbar(
aes(ymin = pi_lwr, ymax = pi_upr),
width = 0
) +
geom_point() +
facet_grid(~ model, labeller = label_both) +
theme_minimal() +
labs(
title = "Predicted vs Actual",
x = "Actual T_norm",
y = "Predicted T_norm"
)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T + T_in, data = df_train)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
df_design_pred <- add_uncertainties(fit_q6, df_design, df_validate)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
df_design_prediction <- add_uncertainties(fit_q6, df_design, df_validate)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
df_design_pred <- add_uncertainties(fit_q6, df_design, df_validate)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
df_design_pred <- add_uncertainties(fit_q6)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
df_design_pred <- add_uncertainties(fit_q6, df_design)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
df_design_pred <- add_uncertainties(fit_q6, fit_baseline)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
df_q6 <- df_psaap %>%
select(T_norm, x, L, W, U_0)
# Scale the numeric variables
df_q6_scaled <- df_q6 %>%
mutate_if(is.numeric, scale)
# Split the data into training and validation sets
set.seed(123)
train_q6 <- df_q6_scaled %>%
sample_frac(0.8)
valid_q6 <- anti_join(df_q6_scaled, train_q6, by = names(df_q6_scaled))
fit_q6 <- glmnet(T_norm ~ ., data = train_q6, family = "gaussian", alpha = 1)
library(tidyverse)
library(modelr)
library(broom)
library(glmnet)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
df_q6 <- df_psaap %>%
select(T_norm, x, L, W, U_0)
# Scale the numeric variables
df_q6_scaled <- df_q6 %>%
mutate_if(is.numeric, scale)
# Split the data into training and validation sets
set.seed(123)
train_q6 <- df_q6_scaled %>%
sample_frac(0.8)
valid_q6 <- anti_join(df_q6_scaled, train_q6, by = names(df_q6_scaled))
fit_q6 <- glmnet(T_norm ~ ., data = train_q6, family = "gaussian", alpha = 1)
library(tidyverse)
library(modelr)
library(broom)
library(glmnet)
## Helper function to compute uncertainty bounds
add_uncertainties <- function(data, model, prefix = "pred", ...) {
df_fit <-
stats::predict(model, data, ...) %>%
as_tibble() %>%
rename_with(~ str_c(prefix, "_", .))
bind_cols(data, df_fit)
}
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
df_q6 <- df_psaap %>%
select(T_norm, x, L, W, U_0)
# Scale the numeric variables
df_q6_scaled <- df_q6 %>%
mutate_if(is.numeric, scale)
# Split the data into training and validation sets
set.seed(123)
train_q6 <- df_q6_scaled %>%
sample_frac(0.8)
valid_q6 <- anti_join(df_q6_scaled, train_q6, by = names(df_q6_scaled))
fit_q6 <- glmnet(T_norm ~ ., data = train_q6, family = "gaussian", alpha = 1)
View(df_design)
View(train_q6)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
df_q6 <- df_psaap %>%
select(T_norm, x, L, W, U_0)
# Scale the numeric variables
df_q6_scaled <- df_q6 %>%
mutate_if(is.numeric, scale)
# Split the data into training and validation sets
set.seed(123)
train_q6 <- df_q6_scaled %>%
sample_frac(0.8)
valid_q6 <- anti_join(df_q6_scaled, train_q6, by = names(df_q6_scaled))
fit_q6 <- glmnet(T_norm ~ ., data = train_q6, family = "gaussian", alpha = 1)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
df_q6 <- df_psaap %>%
select(T_norm, x, L, W, U_0)
# Scale the numeric variables
df_q6_scaled <- df_q6 %>%
mutate_if(is.numeric, scale)
# Split the data into training and validation sets
set.seed(123)
train_q6 <- df_q6_scaled %>%
sample_frac(0.8)
valid_q6 <- anti_join(df_q6_scaled, train_q6, by = names(df_q6_scaled))
fit_q6 <- glmnet(T_norm ~ ., data = train_q6)
library(tidyverse)
library(modelr)
library(broom)
## Helper function to compute uncertainty bounds
add_uncertainties <- function(data, model, prefix = "pred", ...) {
df_fit <-
stats::predict(model, data, ...) %>%
as_tibble() %>%
rename_with(~ str_c(prefix, "_", .))
bind_cols(data, df_fit)
}
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
rsquare(fit_q6, df_validate)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
rsquare(fit_q6, df_validate)
# Compute the residual standard deviation on the validation set
sigma <- sd(residuals(fit_q6, df_validate))
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
rsquare(fit_q6, df_validate)
# Add uncertainties to the prediction using a prediction interval
df_design_uncertainty <- add_uncertainties(df_design, fit_q6, level = pr_level, newdata = df_train)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
rsquare(fit_q6, df_validate)
# Add uncertainties to the prediction using a prediction interval
df_design_uncertainty <- add_uncertainties(df_design, fit_q6, level = pr_level, newdata = df_train, sigma = 1)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
rsquare(fit_q6, df_validate)
sigma <- sd(residuals(fit_q6, df_validate))
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
rsquare(fit_q6, df_validate)
res<-residuals(fit_q6, df_validate)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
rsquare(fit_q6, df_validate)
res<-residuals(fit_q6, df_validate)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
rsquare(fit_q6, df_validate)
# Compute predicted interval for df_design
pred_interval <- interval(fit_q6, newdata = df_design, level = pr_level)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
rsquare(fit_q6, df_validate)
# Compute predicted interval for df_design
pred_interval <- interval(fit_q6, newdata = df_design, level = pr_level)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
rsquare(fit_q6, df_validate)
# Compute predicted interval for df_design
pred_int <- predict(fit_q6, newdata = df_design, interval = "prediction", level = pr_level)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0  , data = df_train)
rsquare(fit_q6, df_validate)
# Compute predicted interval for df_design
pred_int <- predict(fit_q6, newdata = df_design, interval = "prediction", level = pr_level)
# Compute fraction of validation cases within predicted interval
frac_within_interval <- mean(between(df_validate$T_norm, pred_int[1], pred_int[2]))
frac_within_interval
View(pred_int)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0  , data = df_train)
rsquare(fit_q6, df_validate)
# Compute predicted interval for df_design
pred_int <- predict(fit_q6, newdata = df_design, interval = "prediction", level = pr_level)
# Compute fraction of validation cases within predicted interval
frac_within_interval <- between(df_validate$T_norm, pred_int[1], pred_int[2])
frac_within_interval
View(pred_int)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0  , data = df_train)
rsquare(fit_q6, df_validate)
# Compute predicted interval for df_design
pred_int <- predict(fit_q6, newdata = df_design, interval = "prediction", level = pr_level)
# Compute fraction of validation cases within predicted interval
frac_within_interval <- mean(between(df_validate$T_norm, pred_int[1], pred_int[2]))
frac_within_interval
