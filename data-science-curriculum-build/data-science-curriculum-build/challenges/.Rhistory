#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
df_design_pred <- add_uncertainties(fit_q6, fit_baseline)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
df_q6 <- df_psaap %>%
select(T_norm, x, L, W, U_0)
# Scale the numeric variables
df_q6_scaled <- df_q6 %>%
mutate_if(is.numeric, scale)
# Split the data into training and validation sets
set.seed(123)
train_q6 <- df_q6_scaled %>%
sample_frac(0.8)
valid_q6 <- anti_join(df_q6_scaled, train_q6, by = names(df_q6_scaled))
fit_q6 <- glmnet(T_norm ~ ., data = train_q6, family = "gaussian", alpha = 1)
library(tidyverse)
library(modelr)
library(broom)
library(glmnet)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
df_q6 <- df_psaap %>%
select(T_norm, x, L, W, U_0)
# Scale the numeric variables
df_q6_scaled <- df_q6 %>%
mutate_if(is.numeric, scale)
# Split the data into training and validation sets
set.seed(123)
train_q6 <- df_q6_scaled %>%
sample_frac(0.8)
valid_q6 <- anti_join(df_q6_scaled, train_q6, by = names(df_q6_scaled))
fit_q6 <- glmnet(T_norm ~ ., data = train_q6, family = "gaussian", alpha = 1)
library(tidyverse)
library(modelr)
library(broom)
library(glmnet)
## Helper function to compute uncertainty bounds
add_uncertainties <- function(data, model, prefix = "pred", ...) {
df_fit <-
stats::predict(model, data, ...) %>%
as_tibble() %>%
rename_with(~ str_c(prefix, "_", .))
bind_cols(data, df_fit)
}
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
df_q6 <- df_psaap %>%
select(T_norm, x, L, W, U_0)
# Scale the numeric variables
df_q6_scaled <- df_q6 %>%
mutate_if(is.numeric, scale)
# Split the data into training and validation sets
set.seed(123)
train_q6 <- df_q6_scaled %>%
sample_frac(0.8)
valid_q6 <- anti_join(df_q6_scaled, train_q6, by = names(df_q6_scaled))
fit_q6 <- glmnet(T_norm ~ ., data = train_q6, family = "gaussian", alpha = 1)
View(df_design)
View(train_q6)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
df_q6 <- df_psaap %>%
select(T_norm, x, L, W, U_0)
# Scale the numeric variables
df_q6_scaled <- df_q6 %>%
mutate_if(is.numeric, scale)
# Split the data into training and validation sets
set.seed(123)
train_q6 <- df_q6_scaled %>%
sample_frac(0.8)
valid_q6 <- anti_join(df_q6_scaled, train_q6, by = names(df_q6_scaled))
fit_q6 <- glmnet(T_norm ~ ., data = train_q6, family = "gaussian", alpha = 1)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
df_q6 <- df_psaap %>%
select(T_norm, x, L, W, U_0)
# Scale the numeric variables
df_q6_scaled <- df_q6 %>%
mutate_if(is.numeric, scale)
# Split the data into training and validation sets
set.seed(123)
train_q6 <- df_q6_scaled %>%
sample_frac(0.8)
valid_q6 <- anti_join(df_q6_scaled, train_q6, by = names(df_q6_scaled))
fit_q6 <- glmnet(T_norm ~ ., data = train_q6)
library(tidyverse)
library(modelr)
library(broom)
## Helper function to compute uncertainty bounds
add_uncertainties <- function(data, model, prefix = "pred", ...) {
df_fit <-
stats::predict(model, data, ...) %>%
as_tibble() %>%
rename_with(~ str_c(prefix, "_", .))
bind_cols(data, df_fit)
}
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
rsquare(fit_q6, df_validate)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
rsquare(fit_q6, df_validate)
# Compute the residual standard deviation on the validation set
sigma <- sd(residuals(fit_q6, df_validate))
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
rsquare(fit_q6, df_validate)
# Add uncertainties to the prediction using a prediction interval
df_design_uncertainty <- add_uncertainties(df_design, fit_q6, level = pr_level, newdata = df_train)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
rsquare(fit_q6, df_validate)
# Add uncertainties to the prediction using a prediction interval
df_design_uncertainty <- add_uncertainties(df_design, fit_q6, level = pr_level, newdata = df_train, sigma = 1)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
rsquare(fit_q6, df_validate)
sigma <- sd(residuals(fit_q6, df_validate))
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
rsquare(fit_q6, df_validate)
res<-residuals(fit_q6, df_validate)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
rsquare(fit_q6, df_validate)
res<-residuals(fit_q6, df_validate)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
rsquare(fit_q6, df_validate)
# Compute predicted interval for df_design
pred_interval <- interval(fit_q6, newdata = df_design, level = pr_level)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
rsquare(fit_q6, df_validate)
# Compute predicted interval for df_design
pred_interval <- interval(fit_q6, newdata = df_design, level = pr_level)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0 + avg_T , data = df_train)
rsquare(fit_q6, df_validate)
# Compute predicted interval for df_design
pred_int <- predict(fit_q6, newdata = df_design, interval = "prediction", level = pr_level)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0  , data = df_train)
rsquare(fit_q6, df_validate)
# Compute predicted interval for df_design
pred_int <- predict(fit_q6, newdata = df_design, interval = "prediction", level = pr_level)
# Compute fraction of validation cases within predicted interval
frac_within_interval <- mean(between(df_validate$T_norm, pred_int[1], pred_int[2]))
frac_within_interval
View(pred_int)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0  , data = df_train)
rsquare(fit_q6, df_validate)
# Compute predicted interval for df_design
pred_int <- predict(fit_q6, newdata = df_design, interval = "prediction", level = pr_level)
# Compute fraction of validation cases within predicted interval
frac_within_interval <- between(df_validate$T_norm, pred_int[1], pred_int[2])
frac_within_interval
View(pred_int)
# NOTE: No need to change df_design; this is the target the client
#       is considering
df_design <- tibble(x = 1, L = 0.2, W = 0.04, U_0 = 1.0)
# NOTE: This is the level the "probability" level customer wants
pr_level <- 0.8
## TODO: Fit a model, assess the uncertainty in your prediction,
#        use the validation data to check your uncertainty estimates, and
#        make a recommendation on a *dependable range* of values for T_norm
#        at the point `df_design`
fit_q6 <- lm(T_norm ~ x + L + W + U_0  , data = df_train)
rsquare(fit_q6, df_validate)
# Compute predicted interval for df_design
pred_int <- predict(fit_q6, newdata = df_design, interval = "prediction", level = pr_level)
# Compute fraction of validation cases within predicted interval
frac_within_interval <- mean(between(df_validate$T_norm, pred_int[1], pred_int[2]))
frac_within_interval
library(tidyverse)
library(broom)
## TODO: Download the data, move to your data folder, and load it
filename <- "./data/yg821jf8611_ma_statewide_2020_04_01.rds"
df_data <- readRDS(filename)
glimpse(df_data)
## TODO: Determine the factor levels for subject_race and raw_Race
levels(data$subject_race)
## TODO: Determine the factor levels for subject_race and raw_Race
levels(df_data$subject_race)
levels(df_data$raw_Race)
## TODO: Determine the factor levels for subject_race and raw_Race
levels(df_data$subject_race)
levels(df_data$raw_Race)
levels(df_data$race_raw)
levels(df_data$raw_Race)
## TODO: Determine the factor levels for subject_race and raw_Race
levels(df_data$raw_Race)
## TODO: Determine the factor levels for subject_race and raw_Race
levels(df_data$subject_race)
View(df_data)
View(df_data)
## TODO: Devise your own way to test the hypothesis posed above.
## Create a contingency table of the two variables
cont_table <- table(df_data$subject_race, df_data$raw_Race)
## Calculate the proportion of cases where the two variables match
match_prop <- sum(diag(cont_table)) / sum(cont_table)
## Print the proportion
match_prop
## Create a bar plot of mean arrest rate by subject_race
race_summary <-df_ data %>%
## Create a bar plot of mean arrest rate by subject_race
race_summary <-df_data %>%
group_by(subject_race) %>%
summarize(arrest_rate = mean(is_arrested), .groups = "drop") %>%
ggplot(aes(x = subject_race, y = arrest_rate)) +
geom_col() +
labs(x = "Subject Race", y = "Arrest Rate", title = "Arrest Rate by Subject Race")
## Create a bar plot of mean arrest rate by subject_race
race_summary <-df_data %>%
group_by(subject_race) %>%
ggplot(aes(x = subject_race, y = arrest_rate)) +
geom_col() +
labs(x = "Subject Race", y = "Arrest Rate", title = "Arrest Rate by Subject Race")
## Print the bar plot
race_summary
## Create a bar plot of mean arrest rate by subject_race
race_summary <-df_data %>%
group_by(subject_race) %>%
summarize(arrest_rate = mean(arrest_made), .groups = "drop") %>%
ggplot(aes(x = subject_race, y = arrest_rate)) +
geom_col() +
labs(x = "Subject Race", y = "Arrest Rate", title = "Arrest Rate by Subject Race")
## Print the bar plot
race_summary
## Create a bar plot of mean arrest rate by subject_race
race_summary <-df_data %>%
group_by(subject_race) %>%
summarize(arrest_rate = mean(arrest_made)) %>%
ggplot(aes(x = subject_race, y = arrest_rate)) +
geom_col() +
labs(x = "Subject Race", y = "Arrest Rate", title = "Arrest Rate by Subject Race")
## Print the bar plot
race_summary
## Create a bar plot of mean arrest rate by subject_race
race_summary <-df_data %>%
group_by(subject_race) %>%
summarize(arrest_rate = mean(arrest_made)) %>%
ggplot(aes(x = subject_race, y = arrest_rate)) +
geom_point()
## Print the bar plot
race_summary
## Create a bar plot of mean arrest rate by subject_race
race_summary <-df_data %>%
group_by(subject_race) %>%
na.omit(subject_race) %>%
summarize(arrest_rate = mean(arrest_made)) %>%
ggplot(aes(x = subject_race, y = arrest_rate)) +
geom_point()
## Print the bar plot
race_summary
## Create a bar plot of mean arrest rate by subject_race
race_summary <-df_data %>%
group_by(subject_race) %>%
na.omit(subject_race) %>%
summarize(arrest_rate = mean(arrest_made)) %>%
ggplot(aes(x = subject_race, y = arrest_rate)) +
geom_col()
## Print the bar plot
race_summary
## Create a bar plot of mean arrest rate by subject_race
race_summary <-df_data %>%
group_by(subject_race) %>%
na.omit(subject_race) %>%
summarize(arrest_rate = mean(arrest_made)) %>%
ggplot(aes(x = subject_race, y = arrest_rate)) +
geom_col()
## Print the bar plot
race_summary
age_summary <-df_data %>%
group_by(subject_age) %>%
na.omit(subject_age) %>%
summarize(arrest_rate = mean(arrest_made)) %>%
ggplot(aes(x = subject_age, y = arrest_rate)) +
geom_col()
## Print the bar plot
age_summary
## Create a bar plot of mean arrest rate by subject_race
race_summary <-df_data %>%
group_by(subject_race) %>%
na.omit(subject_race) %>%
summarize(arrest_rate = mean(arrest_made)) %>%
ggplot(aes(x = subject_race, y = arrest_rate)) +
geom_col()
## Print the bar plot
race_summary
age_summary <-df_data %>%
group_by(subject_age) %>%
na.omit(subject_age) %>%
summarize(arrest_rate = mean(arrest_made)) %>%
ggplot(aes(x = subject_age, y = arrest_rate)) +
geom_col()
## Print the bar plot
age_summary
sex_summary <-df_data %>%
group_by(subject_sex) %>%
na.omit(subject_sex) %>%
summarize(arrest_rate = mean(arrest_made)) %>%
ggplot(aes(x = subject_sex, y = arrest_rate)) +
geom_col()
## Print the bar plot
sex_summary
## NOTE: No need to edit; inspect the estimated model terms.
fit_q6 <-
glm(
formula = arrest_made ~ subject_age + subject_race + subject_sex,
data = df_data %>%
filter(
!is.na(arrest_made),
subject_race %in% c("white", "black", "hispanic")
),
family = "binomial"
)
fit_q6 %>% tidy()
## TODO: Re-fit the logistic regression, but set "white" as the reference
## level for subject_race
## Refit the logistic regression with "white" as the reference level for subject_race
fit_q7 <- glm(is_arrested ~ subject_race %>% fct_relevel("white") + subject_sex + subject_age, data = data, family = "binomial")
## TODO: Re-fit the logistic regression, but set "white" as the reference
## level for subject_race
## Refit the logistic regression with "white" as the reference level for subject_race
fit_q7 <- glm(is_arrested ~ subject_race %>% fct_relevel("white") + subject_sex + subject_age, data = df_data, family = "binomial")
## TODO: Re-fit the logistic regression, but set "white" as the reference
## level for subject_race
## Refit the logistic regression with "white" as the reference level for subject_race
fit_q7 <- glm(arrest_made ~ subject_race %>% fct_relevel("white") + subject_sex + subject_age, data = df_data, family = "binomial")
## Print the summary of the fitted model
summary(fit_q7)
fit_q7 %>% tidy()
View(df_data)
## TODO: Repeat the modeling above, but control for whether contraband was found
## during the police stop
fit_q8 %>% tidy()
## TODO: Repeat the modeling above, but control for whether contraband was found
## during the police stop
## Fit the logistic regression with contraband as a predictor variable
fit_q8 <- glm(arrest_made ~ subject_race + subject_sex + subject_age + contraband_found, data = df_data, family = "binomial")
fit_q8 %>% tidy()
## Print the summary of the fitted model
summary(fit_q8)
## TODO: Re-fit the logistic regression, but set "white" as the reference
## level for subject_race
## Refit the logistic regression with "white" as the reference level for subject_race
fit_q7 <- glm(arrest_made ~ subject_race %>% fct_relevel("white") + subject_sex + subject_age, data = df_data, family = "binomial")
fit_q7 %>% tidy()
## Print the summary of the fitted model
summary(fit_q7)
search_summary <-df_data %>%
group_by(search_basis) %>%
na.omit(search_basis) %>%
summarize(arrest_rate = mean(arrest_made)) %>%
ggplot(aes(x = search_basis, y = arrest_rate)) +
geom_col()
## Print the bar plot
search_summary
## TODO: Determine the factor levels for subject_race and raw_Race
levels(df_data$subject_race)
levels(df_data$raw_Race)
